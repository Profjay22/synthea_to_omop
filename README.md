# Synthea Prostate Cancer to OMOP ETL Pipeline

A comprehensive Extract-Transform-Load (ETL) pipeline for converting Synthea synthetic prostate cancer patient data to the OMOP Common Data Model (CDM) format. This project provides a robust, configurable, and scalable solution for transforming synthetic healthcare data into a standardized format suitable for observational health data research.

**Note**: While this pipeline is specifically designed and tested for Synthea prostate cancer datasets, the architecture and code can be easily adapted for other Synthea disease modules (diabetes, breast, AML, etc.) by modifying the data extraction and transformation logic.

## Overview

This ETL pipeline transforms synthetic prostate cancer patient data generated by [Synthea](https://github.com/synthetichealth/synthea) into the [OMOP Common Data Model](https://ohdsi.github.io/CommonDataModel/) format. The pipeline supports full automation with comprehensive logging, error handling, and data validation.

**Adaptability**: The pipeline architecture is designed to be easily adapted for other Synthea disease modules. Researchers working with other synthetic datasets can use this codebase as a foundation by modifying the extraction and transformation logic to suit their specific medical domain.

### Key Features

- **Modular Architecture**: Individual processors for each OMOP table with clean separation of concerns
- **Flexible Execution**: Run the complete pipeline or process individual tables
- **Test Mode Support**: Development-friendly testing with sample data
- **Comprehensive Logging**: Detailed progress tracking and error reporting
- **Data Validation**: Foreign key resolution and referential integrity checks
- **Batch Processing**: Configurable batch sizes for optimal performance
- **Configuration Management**: Environment-based configuration for different deployment scenarios

### Supported OMOP Tables

The pipeline processes the following OMOP CDM tables:

- **person** - Patient demographics and basic information
- **location** - Geographic information from patient and provider addresses
- **care_site** - Healthcare organizations and facilities
- **provider** - Healthcare providers and practitioners
- **visit_occurrence** - Healthcare encounters and visits
- **condition_occurrence** - Medical conditions and diagnoses
- **observation** - Clinical observations and assessments
- **observation_period** - Periods of patient observation
- **procedure_occurrence** - Medical procedures and interventions
- **death** - Mortality information
- **drug_exposure** - Medication administrations and prescriptions
- **measurement** - Laboratory tests and clinical measurements

## Prerequisites

### 1. Database Setup

Before running the ETL pipeline, you must set up your PostgreSQL database with the OMOP CDM schema and vocabulary:

```bash
pip install cdm-csv-loader
```

Use the [cdm-csv-loader](https://pypi.org/project/cdm-csv-loader/) package to:
- Create the OMOP CDM schema structure
- Load the OMOP vocabulary files
- Set up the required database tables

Follow the cdm-csv-loader documentation for complete setup instructions.

### 2. Synthea Data Generation

Generate synthetic patient data using Synthea:

```bash
# Example: Generate prostate cancer patient data
java -jar synthea-with-dependencies.jar -p 1000 --exporter.csv.export true -m prostate_cancer

# For other disease modules, replace with appropriate module:
# java -jar synthea-with-dependencies.jar -p 1000 --exporter.csv.export true -m diabetes
# java -jar synthea-with-dependencies.jar -p 1000 --exporter.csv.export true -m cardiovascular
```

### 3. OMOP Vocabulary

Download the OMOP vocabulary from [Athena](https://athena.ohdsi.org/):
- Create an account on Athena
- Download the vocabulary bundle
- Extract to your vocabulary path

## Installation

### 1. Clone the Repository

```bash
git clone <repository-url>
cd synthea-to-omop-pipeline
```

### 2. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Environment Configuration

Create a `.env` file or set environment variables:

```bash
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=your_database_name
DB_USER=your_username
DB_PASSWORD=your_password

# Schema Configuration
SCHEMA_CDM=your_cdm_schema
SCHEMA_VOCAB=your_vocab_schema

# Data Paths
SYNTHEA_DATA_PATH=/path/to/synthea/csv/files
VOCABULARY_PATH=/path/to/omop/vocabulary/files
```

## Usage

### Complete Pipeline Execution

Run the entire ETL pipeline:

```bash
# Production mode - all tables
python main.py --all --clear

# Test mode - limited data for development
python main.py --all --test --clear
```

### Individual Table Processing

Process specific tables:

```bash
# Single table
python main.py --tables person --clear

# Multiple tables
python main.py --tables person location care_site --clear

# Test mode for specific tables
python main.py --tables person provider --test --clear
```

### Command Line Options

| Option | Description |
|--------|-------------|
| `--all` | Run complete pipeline with all tables |
| `--tables TABLE [TABLE ...]` | Process specific tables only |
| `--test` | Run in test mode (limited data) |
| `--clear` | Clear target tables before processing |
| `--batch-size SIZE` | Set batch size for database operations (default: 500) |

## Configuration

### Database Configuration

The pipeline uses the following database configuration pattern:

```python
# config/database.py
class DatabaseConfig:
    def __init__(self):
        self.host = os.getenv('DB_HOST')
        self.port = os.getenv('DB_PORT')
        self.database = os.getenv('DB_NAME')
        self.username = os.getenv('DB_USER')
        self.password = os.getenv('DB_PASSWORD')
        self.schema_cdm = os.getenv('SCHEMA_CDM')
        self.schema_vocab = os.getenv('SCHEMA_VOCAB')
```

### Logging Configuration

Comprehensive logging is configured to track:
- Pipeline execution progress
- Data extraction statistics
- Transformation results
- Loading performance
- Error details and stack traces

## Project Structure

```
synthea-to-omop-pipeline/
├── main.py                          # Main ETL pipeline orchestrator
├── requirements.txt                 # Python dependencies
├── config/
│   ├── database.py                 # Database configuration
│   └── logging.py                  # Logging setup
├── src/
│   ├── extractors/
│   │   └── synthea_extractor.py    # Synthea CSV data extraction
│   ├── transformers/
│   │   ├── person_transformer.py   # Person table transformation
│   │   ├── location_transformer.py # Location table transformation
│   │   └── ...                     # Other table transformers
│   ├── loaders/
│   │   ├── person_loader.py        # Person table loading
│   │   ├── location_loader.py      # Location table loading
│   │   └── ...                     # Other table loaders
│   ├── database/
│   │   └── connection.py           # Database connection management
│   └── utils/
│       ├── logging.py              # Logging utilities
│       └── uuid_converter.py       # UUID handling utilities
└── tests/
    └── ...                         # Unit and integration tests
```

## Data Flow

1. **Extraction**: Read Synthea CSV files from the configured data path
2. **Transformation**: Convert Synthea format to OMOP CDM structure
3. **Validation**: Resolve foreign keys and validate data integrity
4. **Loading**: Bulk insert transformed data into PostgreSQL database
5. **Verification**: Confirm successful data loading and generate statistics

## Adapting for Other Disease Modules

This pipeline was specifically developed and tested with Synthea prostate cancer data, but the modular architecture makes it straightforward to adapt for other disease modules:

### Supported Disease Adaptations
- **Diabetes**: Modify transformers for glucose measurements and diabetes-specific conditions
- **Cardiovascular**: Adapt for cardiac procedures and cardiovascular conditions  
- **Mental Health**: Customize for psychiatric observations and medications
- **Infectious Disease**: Adjust for laboratory tests and antimicrobial treatments
- **General Population**: Use with broad population health datasets

### Adaptation Steps
1. **Update Synthea Generation**: Use appropriate disease module when generating data
2. **Modify Extractors**: Adjust data extraction logic for disease-specific fields
3. **Customize Transformers**: Update transformation rules for domain-specific concepts
4. **Validate Mappings**: Ensure proper OMOP concept mappings for your disease area
5. **Test Pipeline**: Verify data quality and completeness for your specific use case

## Performance Considerations

### Batch Processing

Configure batch sizes based on your system resources:

```bash
# Small batches for limited memory
python main.py --all --batch-size 100

# Large batches for high-performance systems
python main.py --all --batch-size 1000
```

### Database Optimization

- Use appropriate PostgreSQL configuration for bulk loading
- Consider disabling indexes during loading for better performance
- Monitor database connection pool settings

## Error Handling

The pipeline includes comprehensive error handling:

- **Validation Errors**: Data quality issues are logged with specific details
- **Database Errors**: Connection and constraint violations are handled gracefully
- **File Errors**: Missing or corrupt input files are reported clearly
- **Recovery**: Failed tables can be reprocessed individually

## Data Quality

### Validation Checks

- **Referential Integrity**: Foreign key relationships are validated
- **Data Completeness**: Required fields are checked for null values
- **Format Validation**: Dates, codes, and identifiers are validated
- **Duplicate Detection**: Duplicate records are identified and handled

### Quality Reports

After processing, the pipeline generates:
- Record counts for each table
- Transformation success rates
- Data quality metrics
- Error summaries

## Troubleshooting

### Common Issues

1. **Database Connection Errors**
   - Verify database credentials and connectivity
   - Check schema permissions
   - Ensure PostgreSQL is running

2. **Missing Vocabulary Errors**
   - Confirm vocabulary files are loaded using cdm-csv-loader
   - Verify vocabulary schema configuration
   - Check concept mapping tables

3. **Memory Issues**
   - Reduce batch size for large datasets
   - Process tables individually instead of using --all
   - Monitor system memory usage

4. **Foreign Key Violations**
   - Ensure tables are processed in dependency order
   - Verify reference data is loaded correctly
   - Check for data inconsistencies in source files

### Debug Mode

Enable verbose logging for troubleshooting:

```bash
# Set log level to DEBUG in config/logging.py
LOG_LEVEL = "DEBUG"
```

## Development

### Testing

Run tests to validate functionality:

```bash
# Run all tests
python -m pytest tests/

# Run specific test modules
python -m pytest tests/test_transformers.py
```

### Adding New Tables

To add support for additional OMOP tables:

1. Create extractor method in `synthea_extractor.py`
2. Implement transformer class in `src/transformers/`
3. Create loader class in `src/loaders/`
4. Add processing method to main pipeline class
5. Update table list in `main.py`

## Contributing

1. Fork the repository
2. Create a feature branch
3. Implement changes with tests
4. Update documentation
5. Submit a pull request

## Support

For issues and questions:
- Create an issue in the repository
- Check the troubleshooting section
- Review the OMOP CDM documentation
- Consult the Synthea documentation

## Acknowledgments

- [OHDSI](https://ohdsi.org/) for the OMOP Common Data Model
- [Synthea](https://github.com/synthetichealth/synthea) for synthetic patient data generation
- [eHealth Hub](https://pypi.org/project/cdm-csv-loader/) for the CDM CSV loader utility

---

**Note**: This pipeline is designed for research purposes using synthetic data. Ensure compliance with all applicable regulations when working with real patient data.
